#!/usr/bin/env python3
#
# Translated from the Bash script `tsort-modules.orig`.

from glob import glob, escape as glob_escape
import json
import os.path
import sys
from typing import *

import click
import pysh
from pysh import cmd, check_cmd, check_cmd_f, slurp_cmd


# Original script behaved like this:
#   this_file = os.path.realpath(__file__)
#   rootdir = os.path.join(this_file, '../..')
# but this is more convenient to experiment with:
rootdir = os.getcwd()

bindir = f'{rootdir}/node_modules/.bin'


@click.group()
def main() -> None:
    pass


def ltrimstr(prefix: AnyStr, s: AnyStr) -> AnyStr:
    '''Inspired by jq's `ltrimstr` function.'''
    return s[len(prefix):] if s.startswith(prefix) else s


def import_pairs() -> Iterator[Tuple[str, str]]:
    # TODO glob+format similar to shwords's split+format
    sources = glob('{}/src/**/*.js'.format(glob_escape(rootdir)),
                   recursive=True)
    prefix = f'{rootdir}/'
    imports = json.loads(pysh.slurp(
        # TODO hand json.load a file, without slurp
        cmd.run('{}/flow get-imports --json {!@}',  # TODO f-style global
                bindir, sources)))
    # A little more typing than jq's `.[]`, and much more explicit.
    # In particular, this disambiguates that we're expecting an object,
    # not an array.
    for item in imports.values():
        for req in item['requirements']:
            yield (ltrimstr(prefix, req['import']),
                   ltrimstr(prefix, req['path']))


@main.command(name='pairs')
def print_import_pairs() -> None:
    for imp, path in import_pairs():
        print(imp, path)


def sorted_files() -> Iterator[Tuple[str, str]]:
    # TODO unify/dedupe this with print_import_pairs above
    @pysh.filter
    @pysh.output(type='stream')
    def _print_import_pairs(output):
        for imp, path in import_pairs():
            output.write(os.fsencode('{} {}\n'.format(imp, path)))

    for line in (
            _print_import_pairs()
            | cmd.run('tsort', _check=False, _stderr=pysh.DEVNULL)
            | cmd.splitlines()):
        # TODO move decoding inside pipeline
        yield os.fsdecode(line)


@main.command(name='list')
def sorted_ourfiles():
    # Replace `grep` with pure Python where it's on a stream.
    files = [f for f in sorted_files()
             if f.startswith('src/') and f.endswith('js')]
    # But on a bunch of files, real `grep` is much cleaner.
    # TODO don't dump traceback on SIGPIPE, e.g. `tsort-modules list | head`
    check_cmd_f('grep -l @flow -- {files!@}')


def number_lines():
    # TODO some syntax to escape/quote spaces
    return cmd.run('nl -ba -nln -w3 -s{}', ' ')


def with_flow():
    files = [f for f in sorted_files()
             if f.startswith('src/') and f.endswith('js')]
    return cmd.run('grep @flow -- {!@}', files)


@main.command(name='flow')
def with_flow_numbered():
    pysh.to_stdout(with_flow() | number_lines())


@main.command()
def todo():
    pysh.to_stdout(with_flow() | number_lines()
                   | cmd.run('grep -Ev {}', r'@flow strict(\s|$)'))


@main.command()
@click.argument('filename')
def depends(filename):
    for imp, path in import_pairs():
        if path == filename:
            print(imp)


@main.command()
@click.argument('filename')
def rdepends(filename):
    for imp, path in import_pairs():
        if imp == filename:
            print(path)


if __name__ == '__main__':
    main()
